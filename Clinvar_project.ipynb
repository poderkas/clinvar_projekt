{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b70c61f69672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ggplot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numbers\n",
    "from copy import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import sklearn.metrics as metrics\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# TODO\n",
    "pd.set_option('display.max_columns', None)\n",
    "#data = pd.read_csv(\"clinvar_conflicting.csv\")\n",
    "data = pd.read_table(\"clinvar_conflicting_1.txt\",sep=',')\n",
    "data1 = deepcopy(data)\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(data1,color='#FDBB22',sort='descending')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(data1)\n",
    "ax = sns.countplot(x = 'CLASS', data=data1 ,palette=\"icefire\")\n",
    "plt.title('Classification Conflicts in Dataset', fontsize=20, y=1.08)\n",
    "sns.set(font_scale=1)\n",
    "ax.set_xlabel('Target Label Distribution')\n",
    "ax.set_ylabel('Number of Total Variants')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,5)\n",
    "ax2=ax.twinx()\n",
    "ax2.yaxis.tick_left()\n",
    "ax.yaxis.tick_right()\n",
    "ax.set_xticklabels([\"0 (No conflict)\",\"1 (Conflict)\"])\n",
    "ax.yaxis.set_label_position('right')\n",
    "ax2.yaxis.set_label_position('left')\n",
    "ax2.set_ylabel('Frequency [%]')\n",
    "for p in ax.patches:\n",
    "        x=p.get_bbox().get_points()[:,0]\n",
    "        y=p.get_bbox().get_points()[1,1]\n",
    "        ax.annotate('{:.2f}%'.format(100.*y/total), (x.mean(), y), \n",
    "                ha='center', va='bottom') \n",
    "ax2.set_ylim(0,100)\n",
    "ax.set_ylim(0,total)\n",
    "ax2.grid(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ISIKLIKKU LÄHENEMIST VAJAVAD TULBAD\n",
    "\n",
    "#muudame nende tulpade sisu\n",
    "data1[[\"Amino_acids_initial\", \"Amino_acids_replacement\"]] = data1.Amino_acids.str.split(\"/\",expand=True)\n",
    "data1[[\"Codons_initial\", \"Codons_replacement\"]] = data1.Codons.str.split(\"/\",expand=True)\n",
    "\n",
    "data1[\"EXON\"]=data1[\"EXON\"].astype(str)\n",
    "data1[\"INTRON\"]=data1[\"INTRON\"].astype(str)\n",
    "\n",
    "#data1[\"EXON\"].isnull().sum()\n",
    "data1.loc[data1[\"EXON\"] == data1[\"INTRON\"], [\"INTRON\", \"EXON\"]] = np.nan\n",
    "data1.loc[(data1[\"EXON\"]!='nan') & (data1[\"INTRON\"]!='nan') & (data1[\"REF\"].str.len() == 1), [\"INTRON\", \"EXON\"]] = np.nan\n",
    "\n",
    "#viskame välja kõik nan valued\n",
    "data1 = data1[data1['EXON'].notna()]\n",
    "data1 = data1[data1['INTRON'].notna()]\n",
    "\n",
    "data1[[\"EXON_start\", \"EXON_end\"]] = data1.EXON.str.split(\"/\",expand=True)\n",
    "data1[[\"INTRON_start\", \"INTRON_end\"]] = data1.INTRON.str.split(\"/\",expand=True)\n",
    "\n",
    "##CHROM\n",
    "data1[\"CHROM\"]=data1[\"CHROM\"].astype(str)\n",
    "data1.loc[data1[\"CHROM\"] == \"X\", \"CHROM\"] = \"23\"\n",
    "data1.loc[data1[\"CHROM\"] == \"MT\", \"CHROM\"] = \"24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLNVCdata = deepcopy(data1)\n",
    "CLNVCdata = CLNVCdata[~CLNVCdata['CLNVC'].isin(['single_nucleotide_variant'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "ax = sns.countplot(x= 'CLASS', data = CLNVCdata, hue = 'CLNVC',palette=\"rocket\")\n",
    "total=len(data1)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.3f}%'.format(100*height/total),\n",
    "            ha=\"center\",weight=\"bold\",fontsize=15) \n",
    "\n",
    "\n",
    "ax.set_xticklabels(['0 (No conflict)','1 (Conflict)'],fontsize=15, weight=\"bold\")\n",
    "ax.legend(fontsize=20, title=\"Variant type\", title_fontsize=20)\n",
    "ax.set_xlabel(\"Classification\",fontsize=20)\n",
    "ax.set_ylabel(\"Count\",fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#muudame nende tulpade sisu\n",
    "data1[[\"Amino_acids_initial\", \"Amino_acids_replacement\"]] = data1.Amino_acids.str.split(\"/\",expand=True)\n",
    "data1[[\"Codons_initial\", \"Codons_replacement\"]] = data1.Codons.str.split(\"/\",expand=True)\n",
    "\n",
    "data1[\"EXON\"]=data1[\"EXON\"].astype(str)\n",
    "data1[\"INTRON\"]=data1[\"INTRON\"].astype(str)\n",
    "\n",
    "#data1[\"EXON\"].isnull().sum()\n",
    "data1.loc[data1[\"EXON\"] == data1[\"INTRON\"], [\"INTRON\", \"EXON\"]] = np.nan\n",
    "data1.loc[(data1[\"EXON\"]!='nan') & (data1[\"INTRON\"]!='nan') & (data1[\"REF\"].str.len() == 1), [\"INTRON\", \"EXON\"]] = np.nan\n",
    "\n",
    "#viskame välja kõik nan valued\n",
    "data1 = data1[data1['EXON'].notna()]\n",
    "data1 = data1[data1['INTRON'].notna()]\n",
    "\n",
    "data1[[\"EXON_start\", \"EXON_end\"]] = data1.EXON.str.split(\"/\",expand=True)\n",
    "data1[[\"INTRON_start\", \"INTRON_end\"]] = data1.INTRON.str.split(\"/\",expand=True)\n",
    "\n",
    "data1[\"EXON_start\"]=data1[\"EXON_start\"].astype(float)\n",
    "data1[\"EXON_end\"]=data1[\"EXON_end\"].astype(float)\n",
    "data1[\"INTRON_start\"]=data1[\"INTRON_start\"].astype(float)\n",
    "data1[\"INTRON_end\"]=data1[\"INTRON_end\"].astype(float)\n",
    "\n",
    "data1[\"CHROM\"]=data1[\"CHROM\"].astype(str)\n",
    "data1.loc[data1[\"CHROM\"] == \"X\", \"CHROM\"] = \"23\"\n",
    "data1.loc[data1[\"CHROM\"] == \"MT\", \"CHROM\"] = \"24\"\n",
    "\n",
    "#LIHTSASTI DEFINEERITAVAD TULBAD\n",
    "inttüüpi = [\"POS\", \"ORIGIN\", \"CLASS\", \"CHROM\"]\n",
    "floattüüpi = [\"AF_ESP\", \"AF_EXAC\", \"AF_TGP\", \"LoFtool\", \"CADD_PHRED\", \"CADD_RAW\" ,  \"STRAND\", \"BLOSUM62\",\"EXON_start\", \"EXON_end\",\"INTRON_start\", \"INTRON_end\"]\n",
    "strtüüpi = [\"REF\", \"ALT\", \"Consequence\", \"IMPACT\", \"SYMBOL\", \"BIOTYPE\" , \"CLNVC\", \"IMPACT\", \"SIFT\", \"PolyPhen\", \"Amino_acids_initial\", \"Amino_acids_replacement\", \"Codons_initial\", \"Codons_replacement\", \"cDNA_position\" , \"CDS_position\", \"Protein_position\"]\n",
    "\n",
    "\n",
    "def datatypes(inttüüpi, strtüüpi, floattüüpi):\n",
    "  for i in range(len(inttüüpi)):\n",
    "      data1[inttüüpi[i]]=data1[inttüüpi[i]].astype(int)\n",
    "\n",
    "  for i in range(len(strtüüpi)):\n",
    "      data1[strtüüpi[i]]=data1[strtüüpi[i]].astype(str)\n",
    "  \n",
    "  for i in range(len(floattüüpi)):\n",
    "      data1[floattüüpi[i]]=data1[floattüüpi[i]].astype(float).round(5)\n",
    "      \n",
    "datatypes(inttüüpi, strtüüpi, floattüüpi)\n",
    "\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CDNA, CDS ja protein tulpade töötlus\n",
    "data1[[\"cDNA_pos_start\" , \"cDNA_pos_end\"]] = data1.cDNA_position.str.split(\"-\",expand=True)\n",
    "data1[[\"CDS_pos_start\" , \"CDS_pos_end\"]] = data1.CDS_position.str.split(\"-\",expand=True)\n",
    "data1[[\"Protein_pos_start\" , \"Protein_pos_end\"]] = data1.Protein_position.str.split(\"-\",expand=True)\n",
    "\n",
    "floatiks_ja_nan_nimetada = [\"cDNA_pos_start\" , \"cDNA_pos_end\", \"CDS_pos_start\" , \"CDS_pos_end\", \"Protein_pos_start\" , \"Protein_pos_end\"]\n",
    "for i in range(len(floatiks_ja_nan_nimetada)):\n",
    "  data1.loc[data1[floatiks_ja_nan_nimetada[i]] == \"?\", floatiks_ja_nan_nimetada[i]] = \"999999999\"\n",
    "    \n",
    "for i in range(len(floatiks_ja_nan_nimetada)):\n",
    "  data1[floatiks_ja_nan_nimetada[i]]=data1[floatiks_ja_nan_nimetada[i]].astype(float)\n",
    "  data1.loc[data1[floatiks_ja_nan_nimetada[i]].isna(), floatiks_ja_nan_nimetada[i]] = 999999999.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "välja = [\"cDNA_position\",\"CDS_position\",\"Protein_position\",\"Allele\", \"Amino_acids\", \"Codons\", \"EXON\",\"INTRON\", \"CLNDN\", \"CLNDISDB\",\"CLNDNINCL\", \"CLNSIGINCL\", \"CLNDISDBINCL\", \"CLNHGVS\", \"CLNVI\", \"MC\", \"SSR\", \"Feature_type\", \"Feature\", \"DISTANCE\", \"BAM_EDIT\", \"MOTIF_NAME\", \"MOTIF_POS\", \"HIGH_INF_POS\", \"MOTIF_SCORE_CHANGE\"]\n",
    "for i in välja:\n",
    "    data1 = data1.drop(labels=[i], axis=1)\n",
    "\n",
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asendame nendes tulpades nan väärtused tulba keskmisega\n",
    "keskmised=[\"LoFtool\",\"CADD_PHRED\",\"CADD_RAW\",\"BLOSUM62\"]\n",
    "for i in range(len(keskmised)):\n",
    "    data1.loc[data1[keskmised[i]].notna()==False, keskmised[i]] = data1[keskmised[i]].mean()\n",
    "\n",
    "#asendame nendes tulpades nan väärtused 0-ga\n",
    "for i in range(len(floattüüpi)):\n",
    "    data1.loc[data1[floattüüpi[i]].notna()==False, floattüüpi[i]] = 0\n",
    "        \n",
    "data1.AF_ESP[data1.AF_ESP == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mitteInt = floattüüpi + strtüüpi\n",
    "\n",
    "valja = [\"cDNA_position\" , \"CDS_position\", \"Protein_position\"]\n",
    "for i in valja:\n",
    "    mitteInt.remove(i)\n",
    "\n",
    "for i in range(len(mitteInt)):\n",
    "    if data1[mitteInt[i]].isnull().values.any():\n",
    "        print(mitteInt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoding\n",
    "data1 = pd.get_dummies(data1,columns=[\"REF\", \"ALT\", \"CLNVC\", \"Consequence\", \"IMPACT\", \"SYMBOL\", \"BIOTYPE\",\"SIFT\",\n",
    "                                      \"PolyPhen\",\"Amino_acids_initial\", \n",
    "                                      \"Amino_acids_replacement\",\"Codons_initial\",\"Codons_replacement\"], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data1.columns))\n",
    "tulbad = list(data1.columns)\n",
    "for i in range(len(tulbad)):\n",
    "    if \"_nan\" in tulbad[i]:\n",
    "        data1 = data1.drop(tulbad[i], axis=1)\n",
    "        print(tulbad[i])\n",
    "\n",
    "print(len(data1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tulbad = list(data1.columns)\n",
    "for i in range(len(tulbad)):\n",
    "    if data1[tulbad[i]].isnull().values.any():\n",
    "        print(tulbad[i])\n",
    "        \n",
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data1.drop(labels='CLASS',axis=1),data1.CLASS,train_size=0.7,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=3).fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "acc_score=accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy score:\\n%s \" %round(acc_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = dt.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.title('DecisionTreeClassifier ROC')\n",
    "plt.plot(fpr, tpr, 'r', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mudeli fittimine\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=69,\n",
    "                            oob_score=True).fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "acc_score=accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy score:\\n%s \" %round(acc_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(\n",
    "        max_depth=9, n_estimators=100,random_state=0,num_leaves=70,min_data_in_leaf=50)\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "acc_score=accuracy_score(y_pred, y_test)\n",
    "print(\"Accuracy score:\\n%s \" %round(acc_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lgbm.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.title('LGBMClassifier ROC')\n",
    "plt.plot(fpr, tpr, 'r', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aitab välja praakida ebavajalikud featurid\n",
    "\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=data1.columns[:-1])\n",
    "feat_importances.nlargest(15).plot(kind='barh')\n",
    "plt.title(\"Top 15 important features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for overfiting\n",
    "print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} \\nR^2 Validation Score: {:.2f}'.format(rf.score(X_train, y_train), \n",
    "                                                                                             rf.oob_score_,\n",
    "                                                                                             rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairwise correlation graph\n",
    "\n",
    "top15 = data1[[\"AF_EXAC\", \"CADD_PHRED\", \"POS\", \"AF_TGP\", \"LoFtool\", \"AF_ESP\", \"INTRON_end\", \"cDNA_pos_end\", \"CDS_pos_end\",\n",
    "              \"STRAND\", \"BLOSUM62\", \"CHROM\", \"EXON_start\", \"EXON_end\", \"CADD_RAW\"]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "corr = top15.corr()\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.DataFrame(columns=['Feature_name', 'Score'])\n",
    "\n",
    "score = []\n",
    "data1Tulbad = []\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "    data1Tulbad.append(list(data1.columns)[i])\n",
    "    score.append(v)\n",
    "\n",
    "data2['Feature_name'] = data1Tulbad\n",
    "data2[\"Score\"] = score\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.Feature_name[data2.Score.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"Score\"]=data2[\"Score\"].astype(float)\n",
    "data2=data2.sort_values(by=[\"Score\"],ascending=False)\n",
    "\n",
    "print(data2.head(15))\n",
    "print()\n",
    "print(data2.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pairwise correlation graph\n",
    "\n",
    "absValues = deepcopy(data2)\n",
    "absValues.Score = absValues.Score.abs()\n",
    "absValues=absValues.sort_values(by=[\"Score\"],ascending=False)\n",
    "\n",
    "\n",
    "absValues = absValues[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    "bar = sns.barplot(x= absValues[\"Score\"], y=absValues['Feature_name'],palette=\"hls\")\n",
    "bar.set_yticklabels(absValues['Feature_name'], fontsize=12, weight=\"bold\")\n",
    "bar.set_xlabel(\"Score\",fontsize=20)\n",
    "plt.title(\"Features\\n\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
